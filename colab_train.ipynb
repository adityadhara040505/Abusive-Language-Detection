{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41397ac9",
   "metadata": {},
   "source": [
    "# Train Abusive-Language-Detection on Google Colab\n",
    "\n",
    "This notebook automates setup and training on Colab. It: \n",
    "- Installs dependencies from `requirements.txt`\n",
    "- Mounts Google Drive (optional)\n",
    "- Prepares `.env` and data files\n",
    "- Downloads BERT model with `download_model.py`\n",
    "- Runs `python train.py` to start training\n",
    "\n",
    "Notes:\n",
    "- Select GPU runtime: Runtime > Change runtime type > Hardware accelerator: GPU\n",
    "- You can save outputs/checkpoints to Google Drive by mounting it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7780ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Mount Google Drive to save outputs and datasets\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directory in Drive to persist checkpoints (optional)\n",
    "!mkdir -p /content/drive/MyDrive/ALD_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c59eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the repo files are present in Colab workspace (they are if you uploaded the repo)\n",
    "# If running from a GitHub repo, you can clone here instead:\n",
    "# !git clone <your-repo-url> repo && cd repo\n",
    "\n",
    "# Show important files\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe839b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a .env file with default paths (adjust if you mounted Drive)\n",
    "env_content = '''TRAIN_DATASET=data/train.csv\n",
    "TEST_DATASET=data/test.csv\n",
    "OUTPUT_DIR=output/\n",
    "EPOCHS=3\n",
    "BATCH_SIZE=8\n",
    "LOGGING_STEPS=10\n",
    "LEARNING_RATE=2e-5\n",
    "'''\n",
    "with open('.env', 'w') as f:\n",
    "  f.write(env_content)\n",
    "print(open('.env').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Copy dataset from Drive if you placed it there\n",
    "# Uncomment and edit paths if using Drive:\n",
    "# !cp /content/drive/MyDrive/datasets/train.csv data/train.csv\n",
    "# !cp /content/drive/MyDrive/datasets/test.csv data/test.csv\n",
    "\n",
    "# Verify datasets exist\n",
    "!ls -la data || true\n",
    "!head -n 3 data/train.csv || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download bert model if needed\n",
    "# The repo provides `download_model.py` which saves the model under models/bert-base-uncased/\n",
    "!python download_model.py || true\n",
    "!ls -la models/bert-base-uncased || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f600739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "# Adjust epochs and batch size by editing .env or setting env vars in the same cell\n",
    "!python train.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
